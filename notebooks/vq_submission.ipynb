{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_defected = json.load(open('/data/gunsbrother/repos/vq2d-lightning/outputs/batch/2024-11-03/137206/test_predictions.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4461"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "pred_tree = {}\n",
    "for pred_video in result_defected['results']['videos']:\n",
    "    video_uid = pred_video['video_uid']\n",
    "    pred_tree[video_uid] = {}\n",
    "    for pred_clip in pred_video['clips']:\n",
    "        clip_uid = pred_clip['clip_uid']\n",
    "        pred_tree[video_uid][clip_uid] = {}\n",
    "        for pred_qsets in pred_clip['predictions']:\n",
    "            if 'annotation_uid' not in pred_qsets:\n",
    "                pred_tree[video_uid][clip_uid] = None\n",
    "                continue\n",
    "            annotation_uid = pred_qsets['annotation_uid']\n",
    "            pred_tree[video_uid][clip_uid][annotation_uid] = {}\n",
    "            for qset_id, pred_qset in pred_qsets['query_sets'].items():\n",
    "                pred_tree[video_uid][clip_uid][annotation_uid][qset_id] = pred_qset\n",
    "                count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideos\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclips\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_sets\u001b[39m\u001b[38;5;124m'\u001b[39m: {}})\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m qset_id, ann_qsets \u001b[38;5;129;01min\u001b[39;00m ann_annots[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery_sets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 28\u001b[0m     pred_qsets \u001b[38;5;241m=\u001b[39m \u001b[43mpred_tree\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvideo_uid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclip_uid\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mannotation_uid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m qset_id \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pred_qsets:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "result = {\n",
    "    'version': '1.0.5',\n",
    "    'challenge': 'ego4d_vq2d_challenge',\n",
    "    'results': {\n",
    "        'videos': [\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "count = 0\n",
    "anns = json.load(open('/data/datasets/ego4d_data/v2/annotations/vq_test_unannotated.json'))\n",
    "for ann_videos in anns['videos']:\n",
    "    video_uid = ann_videos['video_uid']\n",
    "    result['results']['videos'].append({\n",
    "        'video_uid': video_uid,\n",
    "        'clips': []\n",
    "    })\n",
    "    for ann_clips in ann_videos['clips']:\n",
    "        clip_uid = ann_clips['clip_uid']\n",
    "        result['results']['videos'][-1]['clips'].append({\n",
    "            'clip_uid': clip_uid,\n",
    "            'predictions': []\n",
    "        })\n",
    "        for ann_annots in ann_clips['annotations']:\n",
    "            annotation_uid = ann_annots['annotation_uid']\n",
    "            result['results']['videos'][-1]['clips'][-1]['predictions'].append({'query_sets': {}})\n",
    "            for qset_id, ann_qsets in ann_annots['query_sets'].items():\n",
    "                pred_qsets = pred_tree[video_uid][clip_uid][annotation_uid]\n",
    "                if qset_id not in pred_qsets:\n",
    "                    continue\n",
    "                result['results']['videos'][-1]['clips'][-1]['predictions'][-1]['query_sets'][qset_id] = \\\n",
    "                    pred_tree[video_uid][clip_uid][annotation_uid][qset_id]\n",
    "                count += 1\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vq2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
