{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.chdir(Path('/data/gunsbrother/repos/vq2d-lightning'))\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_ckpt = Path('outputs/batch/2024-09-15/123741/epoch=61-prob_acc=0.7739.ckpt')\n",
    "state_dict = torch.load(p_ckpt, map_location='cpu', weights_only=True)\n",
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['hparams_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_seed': 42,\n",
       " 'batch_size': 8,\n",
       " 'num_workers': 4,\n",
       " 'prefetch_factor': 2,\n",
       " 'base_lr': 0.0003,\n",
       " 'compile': True,\n",
       " 'backbone_precision': 'bf16',\n",
       " 'backbone_fp32_mm_precision': 'medium',\n",
       " 'jid': '123741',\n",
       " 'job_type': 'batch',\n",
       " 'YY': '2024',\n",
       " 'mm': '09',\n",
       " 'dd': '15',\n",
       " 'runtime_outdir': '/data/gunsbrother/repos/vq2d-lightning/outputs/batch/2024-09-15/123741',\n",
       " 'total_bsz': 64,\n",
       " 'max_steps': 22537,\n",
       " 'run_type': 'train',\n",
       " 'trainer': {'devices': 'auto',\n",
       "  'max_epochs': 106,\n",
       "  'max_steps': 22537,\n",
       "  'accumulate_grad_batches': 1,\n",
       "  'precision': '32-true',\n",
       "  'gradient_clip_val': 20.0,\n",
       "  'detect_anomaly': False,\n",
       "  'benchmark': True,\n",
       "  'deterministic': False,\n",
       "  'log_every_n_steps': 1,\n",
       "  'logger': [{'_target_': 'pytorch_lightning.loggers.WandbLogger',\n",
       "    'project': 'ltvu++',\n",
       "    'entity': 'team-khu',\n",
       "    'group': 'smoke_20240915',\n",
       "    'job_type': 'batch',\n",
       "    'name': 'hg-123741',\n",
       "    'tags': [],\n",
       "    'notes': None,\n",
       "    'save_dir': '/data/gunsbrother/repos/vq2d-lightning/outputs/batch/2024-09-15/123741',\n",
       "    'log_model': False}]},\n",
       " 'dataset': {'batch_size': 8,\n",
       "  'num_workers': 4,\n",
       "  'prefetch_factor': 2,\n",
       "  'pin_memory': True,\n",
       "  'persistent_workers': False,\n",
       "  'clips_dir': '/local_datasets/ego4d_data/v2/vq2d_frames/520ss',\n",
       "  'official_anns_dir': '/data/datasets/ego4d_data/v2/annotations',\n",
       "  'flat_anns_dir': './data',\n",
       "  'num_frames': 32,\n",
       "  'frame_interval': 1,\n",
       "  'segment_size': [448, 448],\n",
       "  'query_size': [448, 448],\n",
       "  'query_padding': False,\n",
       "  'query_square': True,\n",
       "  'padding_value': 'zero'},\n",
       " 'optim': {'optimizer': {'_target_': 'torch.optim.AdamW',\n",
       "   'lr': 0.0007999999999999999,\n",
       "   'weight_decay': 0.005},\n",
       "  'lr_scheduler': {'warmup_iter': 1000, 'max_steps': 22537}},\n",
       " 'loss': {'positive_threshold': 0.2,\n",
       "  'logit_scale': 1.0,\n",
       "  'weight_bbox_center': 1.0,\n",
       "  'weight_bbox_hw': 1.0,\n",
       "  'weight_bbox_giou': 0.3,\n",
       "  'weight_prob': 100.0},\n",
       " 'train': {'augments': {'segment': True,\n",
       "   'query': False,\n",
       "   'segment_iter': -1,\n",
       "   'segment_size': [448, 448],\n",
       "   'prob_crop': 1.0,\n",
       "   'crop_scale': 0.8,\n",
       "   'crop_ratio_min': 0.8,\n",
       "   'crop_ratio_max': 1.2,\n",
       "   'prob_color': 1.0,\n",
       "   'brightness': 0.4,\n",
       "   'contrast': 0.4,\n",
       "   'saturation': 0.3,\n",
       "   'hue': 0,\n",
       "   'prob_flip': 0.5}},\n",
       " 'model': {'_target_': 'ltvu.models.VQLoC',\n",
       "  'backbone_name': 'dinov2-hf',\n",
       "  'backbone_type': 'vitb14',\n",
       "  'fix_backbone': True,\n",
       "  'backbone_precision': 'bf16',\n",
       "  'backbone_fp32_mm_precision': 'medium',\n",
       "  'window_transformer': 5,\n",
       "  'resolution_transformer': 8,\n",
       "  'num_anchor_regions': 16,\n",
       "  'num_layers_st_transformer': 3,\n",
       "  'transformer_dropout': 0.0,\n",
       "  'query_size': 448,\n",
       "  'clip_size_fine': 448,\n",
       "  'clip_size_coarse': 448,\n",
       "  'clip_num_frames': 32,\n",
       "  'positive_threshold': 0.2,\n",
       "  'logit_scale': 1.0,\n",
       "  'weight_bbox_center': 1.0,\n",
       "  'weight_bbox_hw': 1.0,\n",
       "  'weight_bbox_giou': 0.3,\n",
       "  'weight_prob': 100.0}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['hyper_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_loop': {'state_dict': {},\n",
       "  'epoch_loop.state_dict': {'_batches_that_stepped': 13144},\n",
       "  'epoch_loop.batch_progress': {'total': {'ready': 13144,\n",
       "    'completed': 13144,\n",
       "    'started': 13144,\n",
       "    'processed': 13144},\n",
       "   'current': {'ready': 212,\n",
       "    'completed': 212,\n",
       "    'started': 212,\n",
       "    'processed': 212},\n",
       "   'is_last_batch': True},\n",
       "  'epoch_loop.scheduler_progress': {'total': {'ready': 13144,\n",
       "    'completed': 13144},\n",
       "   'current': {'ready': 212, 'completed': 212}},\n",
       "  'epoch_loop.automatic_optimization.state_dict': {},\n",
       "  'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 13144,\n",
       "      'completed': 13144},\n",
       "     'current': {'ready': 212, 'completed': 212}},\n",
       "    'zero_grad': {'total': {'ready': 13144,\n",
       "      'completed': 13144,\n",
       "      'started': 13144},\n",
       "     'current': {'ready': 212, 'completed': 212, 'started': 212}}}},\n",
       "  'epoch_loop.manual_optimization.state_dict': {},\n",
       "  'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "    'completed': 0},\n",
       "   'current': {'ready': 0, 'completed': 0}},\n",
       "  'epoch_loop.val_loop.state_dict': {},\n",
       "  'epoch_loop.val_loop.batch_progress': {'total': {'ready': 71,\n",
       "    'completed': 71,\n",
       "    'started': 71,\n",
       "    'processed': 71},\n",
       "   'current': {'ready': 71, 'completed': 71, 'started': 71, 'processed': 71},\n",
       "   'is_last_batch': True},\n",
       "  'epoch_progress': {'total': {'ready': 62,\n",
       "    'completed': 61,\n",
       "    'started': 62,\n",
       "    'processed': 62},\n",
       "   'current': {'ready': 62, 'completed': 61, 'started': 62, 'processed': 62}}},\n",
       " 'validate_loop': {'state_dict': {},\n",
       "  'batch_progress': {'total': {'ready': 0,\n",
       "    'completed': 0,\n",
       "    'started': 0,\n",
       "    'processed': 0},\n",
       "   'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "   'is_last_batch': False}},\n",
       " 'test_loop': {'state_dict': {},\n",
       "  'batch_progress': {'total': {'ready': 0,\n",
       "    'completed': 0,\n",
       "    'started': 0,\n",
       "    'processed': 0},\n",
       "   'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "   'is_last_batch': False}},\n",
       " 'predict_loop': {'state_dict': {},\n",
       "  'batch_progress': {'total': {'ready': 0,\n",
       "    'completed': 0,\n",
       "    'started': 0,\n",
       "    'processed': 0},\n",
       "   'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['loops']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vq2d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
